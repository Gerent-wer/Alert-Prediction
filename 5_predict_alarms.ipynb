{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b89555a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:09.531013Z",
     "end_time": "2023-05-01T21:28:09.789492Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from utils import get_weather\n",
    "from utils import text_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get and preprocess ISW files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb86e69",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:09.633675Z",
     "end_time": "2023-05-01T21:28:09.790454Z"
    }
   },
   "outputs": [],
   "source": [
    "# get article from yesterday\n",
    "today = datetime.date.today()\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "\n",
    "yesterday_day = yesterday.day\n",
    "yesterday_month = yesterday.month\n",
    "yesterday_year = yesterday.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80028a2b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:09.648213Z",
     "end_time": "2023-05-01T21:28:10.385636Z"
    }
   },
   "outputs": [],
   "source": [
    "file = text_processing.get_article_from_yesterday(yesterday_day,yesterday_month,yesterday_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f1ec1e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.385636Z",
     "end_time": "2023-05-01T21:28:10.500713Z"
    }
   },
   "outputs": [],
   "source": [
    "data = text_processing.read_html(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42911601",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.505238Z",
     "end_time": "2023-05-01T21:28:10.516819Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_all_text(data):\n",
    "    pattern = \"\\[(\\d+)\\]\"\n",
    "    data['main_html_v1'] = data['main_html'].apply(lambda x: re.sub(pattern,\"\",str(x)))\n",
    "    data['main_html_v2'] = data['main_html_v1'].apply(lambda x: re.sub(r'http(\\S+.*\\s)',\"\",x))\n",
    "    data['main_html_v3'] = data['main_html_v2'].apply(lambda x: re.sub(r'2022|2023|©2022|©2023|\\xa0|\\n',\"\",x))\n",
    "    data['main_html_v4'] = data['main_html_v3'].apply(lambda x: BeautifulSoup(x).text)\n",
    "    data['main_html_v5'] = data['main_html_v4'].apply(lambda x: text_processing.remove_names_and_dates(x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f59f0ab2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.531378Z",
     "end_time": "2023-05-01T21:28:10.556104Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed = preprocess_all_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af6b1be",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.554050Z",
     "end_time": "2023-05-01T21:28:10.563531Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed = data_preprocessed.drop(['main_html_v1','main_html_v2','main_html_v3','main_html_v4'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5129a561",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.578059Z",
     "end_time": "2023-05-01T21:28:10.776450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dimai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3abf9546",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:10.773440Z",
     "end_time": "2023-05-01T21:28:13.329684Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed['report_text_lemm'] = data_preprocessed['main_html_v5'].apply(lambda x: text_processing.preprocess(x,\"lemm\"))\n",
    "data_preprocessed['report_text_stemm'] = data_preprocessed['main_html_v5'].apply(lambda x: text_processing.preprocess(x,\"stemm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92cd8311",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.334284Z",
     "end_time": "2023-05-01T21:28:13.380458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                          short_url   \n0 2023-04-30  russian_offensive_campaign_assessment_April_30...  \\\n\n                                               title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                          text_title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                            full_url   \n0  /backgrounder/russian-offensive-campaign-asses...  \\\n\n                                           main_html   \n0  [[[ , <p align=\"center\"><strong><br/></strong>...  \\\n\n                                        main_html_v5   \n0   Russian Offensive Campaign Assessment, April ...  \\\n\n                                    report_text_lemm   \n0   russian offens campaign ass april thirty rile...  \\\n\n                                   report_text_stemm  \n0   russian offen campaign assess april thirti ri...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>short_url</th>\n      <th>title</th>\n      <th>text_title</th>\n      <th>full_url</th>\n      <th>main_html</th>\n      <th>main_html_v5</th>\n      <th>report_text_lemm</th>\n      <th>report_text_stemm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-30</td>\n      <td>russian_offensive_campaign_assessment_April_30...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n      <td>Russian Offensive Campaign Assessment, April ...</td>\n      <td>russian offens campaign ass april thirty rile...</td>\n      <td>russian offen campaign assess april thirti ri...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21b756c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.380458Z",
     "end_time": "2023-05-01T21:28:13.391473Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = data_preprocessed['report_text_lemm'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ISW vectorize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b23732",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.399013Z",
     "end_time": "2023-05-01T21:28:13.423598Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "word_count_vector.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "tf_idf_vector = tfidf_transformer.transform(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6067ab90",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.412546Z",
     "end_time": "2023-05-01T21:28:13.468114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<1x664 sparse matrix of type '<class 'numpy.float64'>'\n\twith 664 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b6c871",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.427613Z",
     "end_time": "2023-05-01T21:28:13.514946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<1x664 sparse matrix of type '<class 'numpy.float64'>'\n\twith 664 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab2fc78",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.442137Z",
     "end_time": "2023-05-01T21:28:13.625465Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed['keywords'] = data_preprocessed['report_text_stemm'].apply(lambda x: text_processing.convert_doc_to_vector(x,feature_names,tf_idf_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95ea033d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.458549Z",
     "end_time": "2023-05-01T21:28:13.652083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'command': 0.497,\n 'russian': 0.432,\n 'putin': 0.272,\n 'gerasimov': 0.243,\n 'forc': 0.201,\n 'militari': 0.184,\n 'like': 0.166,\n 'wagner': 0.136,\n 'teplinski': 0.124,\n 'gener': 0.118}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed['keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf547746",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.501259Z",
     "end_time": "2023-05-01T21:28:13.654096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                          short_url   \n0 2023-04-30  russian_offensive_campaign_assessment_April_30...  \\\n\n                                               title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                          text_title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                            full_url   \n0  /backgrounder/russian-offensive-campaign-asses...  \\\n\n                                           main_html   \n0  [[[ , <p align=\"center\"><strong><br/></strong>...  \\\n\n                                        main_html_v5   \n0   Russian Offensive Campaign Assessment, April ...  \\\n\n                                    report_text_lemm   \n0   russian offens campaign ass april thirty rile...  \\\n\n                                   report_text_stemm   \n0   russian offen campaign assess april thirti ri...  \\\n\n                                            keywords  \n0  {'command': 0.497, 'russian': 0.432, 'putin': ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>short_url</th>\n      <th>title</th>\n      <th>text_title</th>\n      <th>full_url</th>\n      <th>main_html</th>\n      <th>main_html_v5</th>\n      <th>report_text_lemm</th>\n      <th>report_text_stemm</th>\n      <th>keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-30</td>\n      <td>russian_offensive_campaign_assessment_April_30...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n      <td>Russian Offensive Campaign Assessment, April ...</td>\n      <td>russian offens campaign ass april thirty rile...</td>\n      <td>russian offen campaign assess april thirti ri...</td>\n      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4c886",
   "metadata": {},
   "source": [
    "#### Part of script: Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f151948d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.519951Z",
     "end_time": "2023-05-01T21:28:13.654096Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed[\"date_datetime\"] = pd.to_datetime(data_preprocessed[\"date\"])\n",
    "data_preprocessed['date_tomorrow_datetime'] = data_preprocessed['date_datetime'].apply(lambda x: x+datetime.timedelta(days=1))\n",
    "data_preprocessed = data_preprocessed.rename(columns = {\"date_datetime\":\"report_date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a31caa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.548647Z",
     "end_time": "2023-05-01T21:28:13.655107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                          short_url   \n0 2023-04-30  russian_offensive_campaign_assessment_April_30...  \\\n\n                                               title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                          text_title   \n0  Russian Offensive Campaign Assessment, April 3...  \\\n\n                                            full_url   \n0  /backgrounder/russian-offensive-campaign-asses...  \\\n\n                                           main_html   \n0  [[[ , <p align=\"center\"><strong><br/></strong>...  \\\n\n                                        main_html_v5   \n0   Russian Offensive Campaign Assessment, April ...  \\\n\n                                    report_text_lemm   \n0   russian offens campaign ass april thirty rile...  \\\n\n                                   report_text_stemm   \n0   russian offen campaign assess april thirti ri...  \\\n\n                                            keywords report_date   \n0  {'command': 0.497, 'russian': 0.432, 'putin': ...  2023-04-30  \\\n\n  date_tomorrow_datetime  \n0             2023-05-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>short_url</th>\n      <th>title</th>\n      <th>text_title</th>\n      <th>full_url</th>\n      <th>main_html</th>\n      <th>main_html_v5</th>\n      <th>report_text_lemm</th>\n      <th>report_text_stemm</th>\n      <th>keywords</th>\n      <th>report_date</th>\n      <th>date_tomorrow_datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-30</td>\n      <td>russian_offensive_campaign_assessment_April_30...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>Russian Offensive Campaign Assessment, April 3...</td>\n      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n      <td>Russian Offensive Campaign Assessment, April ...</td>\n      <td>russian offens campaign ass april thirty rile...</td>\n      <td>russian offen campaign assess april thirti ri...</td>\n      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n      <td>2023-04-30</td>\n      <td>2023-05-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72ff12f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.583785Z",
     "end_time": "2023-05-01T21:28:13.656108Z"
    }
   },
   "outputs": [],
   "source": [
    "data_vectorised = tf_idf_vector.toarray()\n",
    "vectors_df = pd.DataFrame(data_vectorised)\n",
    "vectors_df['date'] = pd.to_datetime(today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e66d70b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.599828Z",
     "end_time": "2023-05-01T21:28:13.680215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6   \n0  0.023685  0.023685  0.011842  0.005921  0.017764  0.005921  0.005921  \\\n\n          7         8         9  ...       655       656       657       658   \n0  0.005921  0.005921  0.005921  ...  0.005921  0.005921  0.005921  0.011842  \\\n\n        659       660       661       662       663       date  \n0  0.011842  0.011842  0.005921  0.011842  0.005921 2023-05-01  \n\n[1 rows x 665 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>655</th>\n      <th>656</th>\n      <th>657</th>\n      <th>658</th>\n      <th>659</th>\n      <th>660</th>\n      <th>661</th>\n      <th>662</th>\n      <th>663</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.023685</td>\n      <td>0.023685</td>\n      <td>0.011842</td>\n      <td>0.005921</td>\n      <td>0.017764</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>...</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>0.005921</td>\n      <td>0.011842</td>\n      <td>0.011842</td>\n      <td>0.011842</td>\n      <td>0.005921</td>\n      <td>0.011842</td>\n      <td>0.005921</td>\n      <td>2023-05-01</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 665 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223b25d3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.636044Z",
     "end_time": "2023-05-01T21:28:13.680215Z"
    }
   },
   "outputs": [],
   "source": [
    "df_isw_short = data_preprocessed[['date','report_text_lemm','keywords','date_tomorrow_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                   report_text_lemm   \n0 2023-04-30   russian offens campaign ass april thirty rile...  \\\n\n                                            keywords date_tomorrow_datetime  \n0  {'command': 0.497, 'russian': 0.432, 'putin': ...             2023-05-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>report_text_lemm</th>\n      <th>keywords</th>\n      <th>date_tomorrow_datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-30</td>\n      <td>russian offens campaign ass april thirty rile...</td>\n      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n      <td>2023-05-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isw_short.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.654096Z",
     "end_time": "2023-05-01T21:28:13.781205Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get weather"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('WEATHER_API_TOKEN')\n",
    "\n",
    "DIR_REGIONS = \"data/0_raw_other_data/regions.csv\"\n",
    "SAVED_FORCASTS = \"data/1_weather_for_12_hours\"\n",
    "\n",
    "df_regions = pd.read_csv(DIR_REGIONS)\n",
    "\n",
    "def save_file(data,city, date):\n",
    "    data_object = json.dumps(data)\n",
    "\n",
    "    # open file for writing, \"w\"\n",
    "    f = open(f\"{SAVED_FORCASTS}/{city}_{date}.json\",\"w\")\n",
    "\n",
    "    # write json object to file\n",
    "    f.write(data_object)\n",
    "\n",
    "    # close file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    f = open(path)\n",
    "\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "    # Closing file\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def get_weather(city, date):\n",
    "\n",
    "    path = f\"{SAVED_FORCASTS}/{city}_{date}.json\"\n",
    "    if (os.path.exists(path)):\n",
    "        jsonData = read_file(path)\n",
    "        return jsonData\n",
    "    location = f\"{city},Ukraine\"\n",
    "    url = f'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{location}/{date}?key={API_KEY}&include=hours&unitGroup=metric&contentType=json'\n",
    "    try:\n",
    "      ResultBytes = urllib.request.urlopen(url)\n",
    "\n",
    "      # Parse the results as JSON\n",
    "      jsonData = json.load(ResultBytes)\n",
    "\n",
    "\n",
    "    except urllib.error.HTTPError  as e:\n",
    "      ErrorInfo= e.read().decode()\n",
    "      print('Error code: ', e.code, ErrorInfo)\n",
    "      sys.exit()\n",
    "    except  urllib.error.URLError as e:\n",
    "      ErrorInfo= e.read().decode()\n",
    "      print('Error code: ', e.code,ErrorInfo)\n",
    "      sys.exit()\n",
    "    save_file(jsonData,city, date)\n",
    "    return jsonData\n",
    "\n",
    "\n",
    "\n",
    "def get_next_date(date):\n",
    "    return (date+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_df_weather(jsonData):\n",
    "    df_data_day = pd.DataFrame(jsonData['days'])\n",
    "    df_data_day = df_data_day[df_data_day.columns[0:33]].add_prefix('day_')\n",
    "    hours_forecast=jsonData['days'][0]['hours']\n",
    "    df_weather_hours = pd.DataFrame(hours_forecast).add_prefix('hour_')\n",
    "    df_weather_hours['hour_int']=pd.to_datetime(df_weather_hours['hour_datetime']).dt.hour\n",
    "    df_weather_hours['key'] = 1\n",
    "    df_data_day['key'] = 1\n",
    "    df_weather_final = pd.merge(df_data_day,df_weather_hours, on='key')\n",
    "    return df_weather_final\n",
    "\n",
    "\n",
    "def get_weather_for_12_hours(city,date):\n",
    "    jsonData = get_weather(city, date.strftime(\"%Y-%m-%d\"))\n",
    "    current_hour = int(date.strftime(\"%H\"))\n",
    "    weather_all_data_day1 = get_df_weather(jsonData)\n",
    "    hours_needed = (weather_all_data_day1['hour_int']>=current_hour)&(weather_all_data_day1['hour_int']<=(current_hour+12))\n",
    "    weather_all_data_day1=weather_all_data_day1[hours_needed]\n",
    "    df_weather_final = weather_all_data_day1\n",
    "    hours_left=12-weather_all_data_day1.shape[0]\n",
    "    if(hours_left>0):\n",
    "        jsonData = get_weather(city, get_next_date(date))\n",
    "        weather_all_data_day2 = get_df_weather(jsonData)\n",
    "        hours_needed_2 = ((weather_all_data_day2['hour_int']<=hours_left))\n",
    "        weather_all_data_day2=weather_all_data_day2[hours_needed_2]\n",
    "        df_weather_final = pd.concat([weather_all_data_day1, weather_all_data_day2], axis=0)\n",
    "    df_weather_final['city']=city\n",
    "    df_final = pd.merge(df_weather_final,df_regions,left_on=\"city\",right_on=\"center_city_en\")\n",
    "\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.677214Z",
     "end_time": "2023-05-01T21:28:13.812119Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db9d5fe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T21:28:13.697406Z",
     "end_time": "2023-05-01T21:28:20.050262Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimai\\AppData\\Local\\Temp\\ipykernel_10896\\1891783052.py:1: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf = pickle.load(open(\"models/tfidf_transformer_v1.pkl\",\"rb\"))\n",
      "C:\\Users\\dimai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\dimai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf = pickle.load(open(\"models/tfidf_transformer_v1.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"models/count_vectorizer_v1.pkl\",\"rb\"))\n",
    "model = pickle.load(open(\"models/training_models/4_rf_3.1f.pkl\",\"rb\"))\n",
    "\n",
    "tfidf_vector = scipy.sparse.load_npz('data/matrix/tfidf_vector_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "434a4f1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 54-57: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeEncodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m result \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m city \u001B[38;5;129;01min\u001B[39;00m cities:\n\u001B[1;32m---> 10\u001B[0m     df_weather_final \u001B[38;5;241m=\u001B[39m \u001B[43mget_weather_for_12_hours\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcity\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# merge\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     df_weather_final[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[27], line 89\u001B[0m, in \u001B[0;36mget_weather_for_12_hours\u001B[1;34m(city, date)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_weather_for_12_hours\u001B[39m(city,date):\n\u001B[1;32m---> 89\u001B[0m     jsonData \u001B[38;5;241m=\u001B[39m \u001B[43mget_weather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrftime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mY-\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mm-\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m     current_hour \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(date\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     91\u001B[0m     weather_all_data_day1 \u001B[38;5;241m=\u001B[39m get_df_weather(jsonData)\n",
      "Cell \u001B[1;32mIn[27], line 53\u001B[0m, in \u001B[0;36mget_weather\u001B[1;34m(city, date)\u001B[0m\n\u001B[0;32m     51\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocation\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m?key=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mAPI_KEY\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m&include=hours&unitGroup=metric&contentType=json\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 53\u001B[0m   ResultBytes \u001B[38;5;241m=\u001B[39m \u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;66;03m# Parse the results as JSON\u001B[39;00m\n\u001B[0;32m     56\u001B[0m   jsonData \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(ResultBytes)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    516\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[0;32m    518\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[1;32m--> 519\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[0;32m    522\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[1;34m(self, req, data)\u001B[0m\n\u001B[0;32m    533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    535\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[1;32m--> 536\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[0;32m    537\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[0;32m    495\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 496\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    497\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    498\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001B[0m, in \u001B[0;36mHTTPSHandler.https_open\u001B[1;34m(self, req)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttps_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[1;32m-> 1391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPSConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_hostname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1348\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[1;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1348\u001B[0m         \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1349\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1350\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m   1351\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1282\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1279\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\u001B[38;5;28mself\u001B[39m, method, url, body\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, headers\u001B[38;5;241m=\u001B[39m{}, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   1280\u001B[0m             encode_chunked\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m   1281\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1282\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1293\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccept-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m header_names:\n\u001B[0;32m   1291\u001B[0m     skips[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mskip_accept_encoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1293\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mputrequest(method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mskips)\n\u001B[0;32m   1295\u001B[0m \u001B[38;5;66;03m# chunked encoding will happen if HTTP/1.1 is used and either\u001B[39;00m\n\u001B[0;32m   1296\u001B[0m \u001B[38;5;66;03m# the caller passes encode_chunked=True or the following\u001B[39;00m\n\u001B[0;32m   1297\u001B[0m \u001B[38;5;66;03m# conditions hold:\u001B[39;00m\n\u001B[0;32m   1298\u001B[0m \u001B[38;5;66;03m# 1. content-length has not been explicitly set\u001B[39;00m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;66;03m# 2. the body is a file or iterable, but not a str or bytes-like\u001B[39;00m\n\u001B[0;32m   1300\u001B[0m \u001B[38;5;66;03m# 3. Transfer-Encoding has NOT been explicitly set by the caller\u001B[39;00m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent-length\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m header_names:\n\u001B[0;32m   1303\u001B[0m     \u001B[38;5;66;03m# only chunk body if not explicitly set for backwards\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m     \u001B[38;5;66;03m# compatibility, assuming the client code is already handling the\u001B[39;00m\n\u001B[0;32m   1305\u001B[0m     \u001B[38;5;66;03m# chunking\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1131\u001B[0m, in \u001B[0;36mHTTPConnection.putrequest\u001B[1;34m(self, method, url, skip_host, skip_accept_encoding)\u001B[0m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_path(url)\n\u001B[0;32m   1129\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (method, url, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_http_vsn_str)\n\u001B[1;32m-> 1131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_encode_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_http_vsn \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m11\u001B[39m:\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;66;03m# Issue some standard headers for better HTTP/1.1 compliance\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_host:\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# this header is issued *only* for HTTP/1.1\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;66;03m# connections. more specifically, this means it is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1148\u001B[0m         \u001B[38;5;66;03m# but the host of the actual URL, not the host of the\u001B[39;00m\n\u001B[0;32m   1149\u001B[0m         \u001B[38;5;66;03m# proxy.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1211\u001B[0m, in \u001B[0;36mHTTPConnection._encode_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_encode_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, request):\n\u001B[0;32m   1210\u001B[0m     \u001B[38;5;66;03m# ASCII also helps prevent CVE-2019-9740.\u001B[39;00m\n\u001B[1;32m-> 1211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mascii\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mUnicodeEncodeError\u001B[0m: 'ascii' codec can't encode characters in position 54-57: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "cities = ['Крим','Вінниччина','Волинь','Дніпропетровщина','Донеччина','Житомирщина','Закарпаття', 'Запоріжжя',\n",
    "          'Івано-Франківщина','Київщина','Кіровоградщина','Луганщина','Львівщина','Миколаївщина','Одещина','Полтавщина',\n",
    "          'Рівненщина','Сумщина','Тернопільщина','Харківщина','Херсонщина','Хмельниччина','Черкащина',\n",
    "          'Буковина','Чернігівщина']\n",
    "\n",
    "date = today = datetime.date.today()\n",
    "result = {}\n",
    "for city in cities:\n",
    "\n",
    "    df_weather_final = get_weather_for_12_hours(city,date)\n",
    "\n",
    "    # merge\n",
    "    df_weather_final['key']=1\n",
    "    df_isw_short['key']=1\n",
    "    df_all = df_weather_final.merge(df_isw_short, how = 'left', left_on = 'key', right_on = 'key')\n",
    "\n",
    "    # drop\n",
    "    to_drop=['key','date','date_tomorrow_datetime','keywords','report_text_lemm']\n",
    "    if 'sunrise' in df_all.columns:\n",
    "        exceptions = ['sunset','sunrise']\n",
    "        to_drop.extend(exceptions)\n",
    "    df_weather_matrix_v1 = df_all.drop(to_drop, axis = 1)\n",
    "\n",
    "    # final dataset\n",
    "    df_weather_matrix_v1= df_weather_matrix_v1[['day_tempmax', 'day_tempmin', 'day_temp', 'day_dew', 'day_humidity',\n",
    "           'day_precip', 'day_precipcover', 'day_solarradiation',\n",
    "           'day_solarenergy', 'day_uvindex', 'hour_temp', 'hour_humidity',\n",
    "           'hour_dew', 'hour_precip', 'hour_precipprob', 'hour_snow',\n",
    "           'hour_snowdepth', 'hour_windgust', 'hour_windspeed', 'hour_winddir',\n",
    "           'hour_pressure', 'hour_visibility', 'hour_cloudcover',\n",
    "           'hour_solarradiation', 'hour_uvindex', 'hour_severerisk','region_id','hour_datetimeEpoch']]\n",
    "\n",
    "    cv_vector_model = cv.transform(df_all['report_text_lemm'].values.astype('U'))\n",
    "    #TF_IDF_MODEL = tfidf.transform(cv_vector_model)\n",
    "\n",
    "    df_weather_matrix_v1_csr = scipy.sparse.csr_matrix(df_weather_matrix_v1)\n",
    "    df_all_data_csr = scipy.sparse.hstack((df_weather_matrix_v1_csr, tfidf_vector), format='csr')\n",
    "\n",
    "    #predict\n",
    "    predicted = model.predict(df_all_data_csr)\n",
    "    current_time = pd.Timestamp.now()\n",
    "\n",
    "    hours = []\n",
    "    for i in range(12):\n",
    "        hour = current_time + datetime.timedelta(hours=i)\n",
    "        hours.append(hour) \n",
    "\n",
    "    result[city] = dict(zip(hours, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe15298",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.to_csv('results.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
