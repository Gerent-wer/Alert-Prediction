{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d45e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b89555a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:09.789492Z",
     "start_time": "2023-05-01T21:28:09.531013Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from utils import get_weather\n",
    "from utils import text_processing\n",
    "\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5b50a",
   "metadata": {},
   "source": [
    "### Get and preprocess ISW files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb86e69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:09.790454Z",
     "start_time": "2023-05-01T21:28:09.633675Z"
    }
   },
   "outputs": [],
   "source": [
    "# get article from yesterday\n",
    "today = datetime.date.today()\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "\n",
    "yesterday_day = yesterday.day\n",
    "yesterday_month = yesterday.month\n",
    "yesterday_year = yesterday.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80028a2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.385636Z",
     "start_time": "2023-05-01T21:28:09.648213Z"
    }
   },
   "outputs": [],
   "source": [
    "file = text_processing.get_article_from_yesterday(yesterday_day,yesterday_month,yesterday_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f1ec1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.500713Z",
     "start_time": "2023-05-01T21:28:10.385636Z"
    }
   },
   "outputs": [],
   "source": [
    "data = text_processing.read_html(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42911601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.516819Z",
     "start_time": "2023-05-01T21:28:10.505238Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_all_text(data):\n",
    "    pattern = \"\\[(\\d+)\\]\"\n",
    "    data['main_html_v1'] = data['main_html'].apply(lambda x: re.sub(pattern,\"\",str(x)))\n",
    "    data['main_html_v2'] = data['main_html_v1'].apply(lambda x: re.sub(r'http(\\S+.*\\s)',\"\",x))\n",
    "    data['main_html_v3'] = data['main_html_v2'].apply(lambda x: re.sub(r'2022|2023|©2022|©2023|\\xa0|\\n',\"\",x))\n",
    "    data['main_html_v4'] = data['main_html_v3'].apply(lambda x: BeautifulSoup(x).text)\n",
    "    data['main_html_v5'] = data['main_html_v4'].apply(lambda x: text_processing.remove_names_and_dates(x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59f0ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.556104Z",
     "start_time": "2023-05-01T21:28:10.531378Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed = preprocess_all_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af6b1be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.563531Z",
     "start_time": "2023-05-01T21:28:10.554050Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed = data_preprocessed.drop(['main_html_v1','main_html_v2','main_html_v3','main_html_v4'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5129a561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:10.776450Z",
     "start_time": "2023-05-01T21:28:10.578059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nikita_voitishyn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abf9546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.329684Z",
     "start_time": "2023-05-01T21:28:10.773440Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed['report_text_lemm'] = data_preprocessed['main_html_v5'].apply(lambda x: text_processing.preprocess(x,\"lemm\"))\n",
    "data_preprocessed['report_text_stemm'] = data_preprocessed['main_html_v5'].apply(lambda x: text_processing.preprocess(x,\"stemm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92cd8311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.380458Z",
     "start_time": "2023-05-01T21:28:13.334284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>short_url</th>\n",
       "      <th>title</th>\n",
       "      <th>text_title</th>\n",
       "      <th>full_url</th>\n",
       "      <th>main_html</th>\n",
       "      <th>main_html_v5</th>\n",
       "      <th>report_text_lemm</th>\n",
       "      <th>report_text_stemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>russian_offensive_campaign_assessment_April_30...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n",
       "      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April ...</td>\n",
       "      <td>russian offens campaign ass april thirty rile...</td>\n",
       "      <td>russian offen campaign assess april thirti ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                          short_url  \\\n",
       "0 2023-04-30  russian_offensive_campaign_assessment_April_30...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                          text_title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                            full_url  \\\n",
       "0  /backgrounder/russian-offensive-campaign-asses...   \n",
       "\n",
       "                                           main_html  \\\n",
       "0  [[[ , <p align=\"center\"><strong><br/></strong>...   \n",
       "\n",
       "                                        main_html_v5  \\\n",
       "0   Russian Offensive Campaign Assessment, April ...   \n",
       "\n",
       "                                    report_text_lemm  \\\n",
       "0   russian offens campaign ass april thirty rile...   \n",
       "\n",
       "                                   report_text_stemm  \n",
       "0   russian offen campaign assess april thirti ri...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21b756c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.391473Z",
     "start_time": "2023-05-01T21:28:13.380458Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = data_preprocessed['report_text_lemm'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1280d2",
   "metadata": {},
   "source": [
    "### ISW vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b23732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.423598Z",
     "start_time": "2023-05-01T21:28:13.399013Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "word_count_vector.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "tf_idf_vector = tfidf_transformer.transform(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6067ab90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.468114Z",
     "start_time": "2023-05-01T21:28:13.412546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x664 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 664 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b6c871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.514946Z",
     "start_time": "2023-05-01T21:28:13.427613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x664 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 664 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab2fc78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.625465Z",
     "start_time": "2023-05-01T21:28:13.442137Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed['keywords'] = data_preprocessed['report_text_stemm'].apply(lambda x: text_processing.convert_doc_to_vector(x,feature_names,tf_idf_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ea033d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.652083Z",
     "start_time": "2023-05-01T21:28:13.458549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'command': 0.497,\n",
       " 'russian': 0.432,\n",
       " 'putin': 0.272,\n",
       " 'gerasimov': 0.243,\n",
       " 'forc': 0.201,\n",
       " 'militari': 0.184,\n",
       " 'like': 0.166,\n",
       " 'wagner': 0.136,\n",
       " 'teplinski': 0.124,\n",
       " 'gener': 0.118}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed['keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf547746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.654096Z",
     "start_time": "2023-05-01T21:28:13.501259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>short_url</th>\n",
       "      <th>title</th>\n",
       "      <th>text_title</th>\n",
       "      <th>full_url</th>\n",
       "      <th>main_html</th>\n",
       "      <th>main_html_v5</th>\n",
       "      <th>report_text_lemm</th>\n",
       "      <th>report_text_stemm</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>russian_offensive_campaign_assessment_April_30...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n",
       "      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April ...</td>\n",
       "      <td>russian offens campaign ass april thirty rile...</td>\n",
       "      <td>russian offen campaign assess april thirti ri...</td>\n",
       "      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                          short_url  \\\n",
       "0 2023-04-30  russian_offensive_campaign_assessment_April_30...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                          text_title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                            full_url  \\\n",
       "0  /backgrounder/russian-offensive-campaign-asses...   \n",
       "\n",
       "                                           main_html  \\\n",
       "0  [[[ , <p align=\"center\"><strong><br/></strong>...   \n",
       "\n",
       "                                        main_html_v5  \\\n",
       "0   Russian Offensive Campaign Assessment, April ...   \n",
       "\n",
       "                                    report_text_lemm  \\\n",
       "0   russian offens campaign ass april thirty rile...   \n",
       "\n",
       "                                   report_text_stemm  \\\n",
       "0   russian offen campaign assess april thirti ri...   \n",
       "\n",
       "                                            keywords  \n",
       "0  {'command': 0.497, 'russian': 0.432, 'putin': ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4c886",
   "metadata": {},
   "source": [
    "#### Part of script: Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f151948d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.654096Z",
     "start_time": "2023-05-01T21:28:13.519951Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessed[\"date_datetime\"] = pd.to_datetime(data_preprocessed[\"date\"])\n",
    "data_preprocessed['date_tomorrow_datetime'] = data_preprocessed['date_datetime'].apply(lambda x: x+datetime.timedelta(days=1))\n",
    "data_preprocessed = data_preprocessed.rename(columns = {\"date_datetime\":\"report_date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1a31caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.655107Z",
     "start_time": "2023-05-01T21:28:13.548647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>short_url</th>\n",
       "      <th>title</th>\n",
       "      <th>text_title</th>\n",
       "      <th>full_url</th>\n",
       "      <th>main_html</th>\n",
       "      <th>main_html_v5</th>\n",
       "      <th>report_text_lemm</th>\n",
       "      <th>report_text_stemm</th>\n",
       "      <th>keywords</th>\n",
       "      <th>report_date</th>\n",
       "      <th>date_tomorrow_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>russian_offensive_campaign_assessment_April_30...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April 3...</td>\n",
       "      <td>/backgrounder/russian-offensive-campaign-asses...</td>\n",
       "      <td>[[[ , &lt;p align=\"center\"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;...</td>\n",
       "      <td>Russian Offensive Campaign Assessment, April ...</td>\n",
       "      <td>russian offens campaign ass april thirty rile...</td>\n",
       "      <td>russian offen campaign assess april thirti ri...</td>\n",
       "      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                          short_url  \\\n",
       "0 2023-04-30  russian_offensive_campaign_assessment_April_30...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                          text_title  \\\n",
       "0  Russian Offensive Campaign Assessment, April 3...   \n",
       "\n",
       "                                            full_url  \\\n",
       "0  /backgrounder/russian-offensive-campaign-asses...   \n",
       "\n",
       "                                           main_html  \\\n",
       "0  [[[ , <p align=\"center\"><strong><br/></strong>...   \n",
       "\n",
       "                                        main_html_v5  \\\n",
       "0   Russian Offensive Campaign Assessment, April ...   \n",
       "\n",
       "                                    report_text_lemm  \\\n",
       "0   russian offens campaign ass april thirty rile...   \n",
       "\n",
       "                                   report_text_stemm  \\\n",
       "0   russian offen campaign assess april thirti ri...   \n",
       "\n",
       "                                            keywords report_date  \\\n",
       "0  {'command': 0.497, 'russian': 0.432, 'putin': ...  2023-04-30   \n",
       "\n",
       "  date_tomorrow_datetime  \n",
       "0             2023-05-01  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ff12f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.656108Z",
     "start_time": "2023-05-01T21:28:13.583785Z"
    }
   },
   "outputs": [],
   "source": [
    "data_vectorised = tf_idf_vector.toarray()\n",
    "vectors_df = pd.DataFrame(data_vectorised)\n",
    "vectors_df['date'] = pd.to_datetime(today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e66d70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.680215Z",
     "start_time": "2023-05-01T21:28:13.599828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>655</th>\n",
       "      <th>656</th>\n",
       "      <th>657</th>\n",
       "      <th>658</th>\n",
       "      <th>659</th>\n",
       "      <th>660</th>\n",
       "      <th>661</th>\n",
       "      <th>662</th>\n",
       "      <th>663</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.023685  0.023685  0.011842  0.005921  0.017764  0.005921  0.005921   \n",
       "\n",
       "          7         8         9  ...       655       656       657       658  \\\n",
       "0  0.005921  0.005921  0.005921  ...  0.005921  0.005921  0.005921  0.011842   \n",
       "\n",
       "        659       660       661       662       663       date  \n",
       "0  0.011842  0.011842  0.005921  0.011842  0.005921 2023-05-01  \n",
       "\n",
       "[1 rows x 665 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223b25d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.680215Z",
     "start_time": "2023-05-01T21:28:13.636044Z"
    }
   },
   "outputs": [],
   "source": [
    "df_isw_short = data_preprocessed[['date','report_text_lemm','keywords','date_tomorrow_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdbd90ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.781205Z",
     "start_time": "2023-05-01T21:28:13.654096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>report_text_lemm</th>\n",
       "      <th>keywords</th>\n",
       "      <th>date_tomorrow_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>russian offens campaign ass april thirty rile...</td>\n",
       "      <td>{'command': 0.497, 'russian': 0.432, 'putin': ...</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                   report_text_lemm  \\\n",
       "0 2023-04-30   russian offens campaign ass april thirty rile...   \n",
       "\n",
       "                                            keywords date_tomorrow_datetime  \n",
       "0  {'command': 0.497, 'russian': 0.432, 'putin': ...             2023-05-01  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isw_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c52c99",
   "metadata": {},
   "source": [
    "### Get weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1981e5cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:13.812119Z",
     "start_time": "2023-05-01T21:28:13.677214Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()\n",
    "#API_KEY = os.getenv('WEATHER_API_TOKEN')\n",
    "\n",
    "API_KEY = \"9TS2B3LDPRU8UYW7QBPLEUV6S\"\n",
    "\n",
    "DIR_REGIONS = \"data/0_raw_other_data/regions.csv\"\n",
    "SAVED_FORCASTS = \"data/1_weather_for_12_hours\"\n",
    "\n",
    "df_regions = pd.read_csv(DIR_REGIONS)\n",
    "\n",
    "def save_file(data,city, date):\n",
    "    data_object = json.dumps(data)\n",
    "\n",
    "    # open file for writing, \"w\"\n",
    "    f = open(f\"{SAVED_FORCASTS}/{city}_{date}.json\",\"w\")\n",
    "\n",
    "    # write json object to file\n",
    "    f.write(data_object)\n",
    "\n",
    "    # close file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    f = open(path)\n",
    "\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "    # Closing file\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def get_weather(region,today_date):\n",
    "    level = \"hours\"\n",
    "    country = \"Ukraine\"\n",
    "    start_date = end_date = today_date\n",
    "\n",
    "    city = df_regions[df_regions[\"region_alt\"] == region][\"center_city_en\"].values[0]\n",
    "    location = f\"{city},{country}\"\n",
    "\n",
    "    file_name = f\"weather_{city.lower()}_{start_date}_{end_date}.json\"\n",
    "\n",
    "    if not os.path.isfile(f\"{SAVED_FORCASTS}/{file_name}\"):\n",
    "        url_base_url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline\"\n",
    "        url_key = f\"?key={API_KEY}\"\n",
    "        url_location = location\n",
    "        url_start_data = start_date\n",
    "        url_end_data = end_date\n",
    "        url_level = level\n",
    "\n",
    "        url = f\"{url_base_url}/{url_location}/{url_start_data}/{url_end_data}/{url_key}&include=hours&unitGroup=metric&contentType=json\"\n",
    "\n",
    "        response = requests.request(\"GET\", url)\n",
    "        city_weather_json = response.json()\n",
    "\n",
    "        with open(f\"{SAVED_FORCASTS}/{file_name}\", 'w') as outfile:\n",
    "            json.dump(city_weather_json, outfile)\n",
    "            #outfile.write(city_weather_json)\n",
    "\n",
    "    else:\n",
    "        print(f\"Weather data for the \\nregion {region}; \\nstart_date {start_date}; \\nend_date {end_date}; \\nis ready\")\n",
    "\n",
    "\n",
    "    with open(f\"{SAVED_FORCASTS}/{file_name}\") as outfile:\n",
    "        weather_json = json.load(outfile)\n",
    "\n",
    "    hours_weather_json = []\n",
    "\n",
    "    for day in weather_json['days']:\n",
    "        for hour in day['hours']:\n",
    "            hours_weather_json.append(hour)\n",
    "\n",
    "    hours_df = pd.DataFrame(hours_weather_json)\n",
    "\n",
    "    return weather_json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_next_date(date):\n",
    "    return (date+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_df_weather(jsonData):\n",
    "    df_data_day = pd.DataFrame(jsonData['days'])\n",
    "    df_data_day = df_data_day[df_data_day.columns[0:33]].add_prefix('day_')\n",
    "    hours_forecast=jsonData['days'][0]['hours']\n",
    "    df_weather_hours = pd.DataFrame(hours_forecast).add_prefix('hour_')\n",
    "    df_weather_hours['hour_int']=pd.to_datetime(df_weather_hours['hour_datetime']).dt.hour\n",
    "    df_weather_hours['key'] = 1\n",
    "    df_data_day['key'] = 1\n",
    "    df_weather_final = pd.merge(df_data_day,df_weather_hours, on='key')\n",
    "    return df_weather_final\n",
    "\n",
    "\n",
    "def get_weather_for_12_hours(city,date):\n",
    "    jsonData = get_weather(city, date.strftime(\"%Y-%m-%d\"))\n",
    "    current_hour = int(date.strftime(\"%H\"))\n",
    "    weather_all_data_day1 = get_df_weather(jsonData)\n",
    "    hours_needed = (weather_all_data_day1['hour_int']>=current_hour)&(weather_all_data_day1['hour_int']<=(current_hour+12))\n",
    "    weather_all_data_day1=weather_all_data_day1[hours_needed]\n",
    "    df_weather_final = weather_all_data_day1\n",
    "    hours_left=12-weather_all_data_day1.shape[0]\n",
    "    if(hours_left>0):\n",
    "        jsonData = get_weather(city, get_next_date(date))\n",
    "        weather_all_data_day2 = get_df_weather(jsonData)\n",
    "        hours_needed_2 = ((weather_all_data_day2['hour_int']<=hours_left))\n",
    "        weather_all_data_day2=weather_all_data_day2[hours_needed_2]\n",
    "        df_weather_final = pd.concat([weather_all_data_day1, weather_all_data_day2], axis=0)\n",
    "    df_weather_final['city']=city\n",
    "    df_final = pd.merge(df_weather_final,df_regions,left_on=\"city\",right_on=\"center_city_en\")\n",
    "\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92fdd2c",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5db9d5fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T21:28:20.050262Z",
     "start_time": "2023-05-01T21:28:13.697406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikita_voitishyn/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/Users/nikita_voitishyn/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf = pickle.load(open(\"models/tfidf_transformer_v1.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"models/count_vectorizer_v1.pkl\",\"rb\"))\n",
    "model = pickle.load(open(\"models/4_rf_3.1f.pkl\",\"rb\"))\n",
    "\n",
    "tfidf_vector = scipy.sparse.load_npz('data/matrix/tfidf_vector_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data for the \n",
      "region Крим; \n",
      "start_date 2023-05-01; \n",
      "end_date 2023-05-01; \n",
      "is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/jfstwx3n6x5bg_8mdp2wq81w0000gn/T/ipykernel_20088/3225205747.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_isw_short['key']=1\n"
     ]
    }
   ],
   "source": [
    "cities = ['Крим','Вінниччина','Волинь','Дніпропетровщина','Донеччина','Житомирщина','Закарпаття', 'Запоріжжя',\n",
    "          'Івано-Франківщина','Київщина','Кіровоградщина','Луганщина','Львівщина','Миколаївщина','Одещина','Полтавщина',\n",
    "          'Рівненщина','Сумщина','Тернопільщина','Харківщина','Херсонщина','Хмельниччина','Черкащина',\n",
    "          'Буковина','Чернігівщина']\n",
    "\n",
    "date = today = datetime.date.today()\n",
    "result = {}\n",
    "for city in cities:\n",
    "\n",
    "    df_weather_final = get_weather_for_12_hours(city,date)\n",
    "\n",
    "    # merge\n",
    "    df_weather_final['key']=1\n",
    "    df_isw_short['key']=1\n",
    "    df_all = df_weather_final.merge(df_isw_short, how = 'left', left_on = 'key', right_on = 'key')\n",
    "\n",
    "    # drop\n",
    "    to_drop=['key','date','date_tomorrow_datetime','keywords','report_text_lemm']\n",
    "    if 'sunrise' in df_all.columns:\n",
    "        exceptions = ['sunset','sunrise']\n",
    "        to_drop.extend(exceptions)\n",
    "    df_weather_matrix_v1 = df_all.drop(to_drop, axis = 1)\n",
    "\n",
    "    # final dataset\n",
    "    df_weather_matrix_v1= df_weather_matrix_v1[['day_tempmax', 'day_tempmin', 'day_temp', 'day_dew', 'day_humidity',\n",
    "           'day_precip', 'day_precipcover', 'day_solarradiation',\n",
    "           'day_solarenergy', 'day_uvindex', 'hour_temp', 'hour_humidity',\n",
    "           'hour_dew', 'hour_precip', 'hour_precipprob', 'hour_snow',\n",
    "           'hour_snowdepth', 'hour_windgust', 'hour_windspeed', 'hour_winddir',\n",
    "           'hour_pressure', 'hour_visibility', 'hour_cloudcover',\n",
    "           'hour_solarradiation', 'hour_uvindex', 'hour_severerisk','region_id','hour_datetimeEpoch']]\n",
    "\n",
    "    cv_vector_model = cv.transform(df_all['report_text_lemm'].values.astype('U'))\n",
    "    #TF_IDF_MODEL = tfidf.transform(cv_vector_model)\n",
    "\n",
    "    df_weather_matrix_v1_csr = scipy.sparse.csr_matrix(df_weather_matrix_v1)\n",
    "    df_all_data_csr = scipy.sparse.hstack((df_weather_matrix_v1_csr, tfidf_vector), format='csr')\n",
    "\n",
    "    #predict\n",
    "    predicted = model.predict(df_all_data_csr)\n",
    "    current_time = pd.Timestamp.now()\n",
    "\n",
    "    hours = []\n",
    "    for i in range(12):\n",
    "        hour = current_time + datetime.timedelta(hours=i)\n",
    "        hours.append(hour) \n",
    "\n",
    "    result[city] = dict(zip(hours, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe15298",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.to_csv('results.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
